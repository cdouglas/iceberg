# Description: Connections Configuration
---
version: 1
connections:
#- id: spark_0
#  driver: org.apache.hive.jdbc.HiveDriver
#  url: jdbc:hive2://spark-thrift:10000
#  max_num_retries: 3
#  show_warnings: true
##  #username: ${DATABASE_USER:-spark_admin}
##  #password: ${DATABASE_PASSWORD}
#- id: spark_1
#  type: jdbc
#  driver: org.apache.hive.jdbc.HiveDriver
#  url: jdbc:hive2://spark-thirft:10001
#  #username: admin
#  #password: p@ssw0rd1
- id: spark_2
  type: spark
  url: spark://spark-master:7077
  config:
    spark.worker.timeout: "60"
    spark.sql.catalog.local_original_iceberg: "org.apache.iceberg.spark.SparkCatalog"
    spark.sql.extensions: "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"
    spark.sql.catalog.spark_catalog: "org.apache.iceberg.spark.SparkSessionCatalog"
    spark.sql.catalog.spark_catalog.type: "hadoop"
    spark.sql.catalog.spark_catalog.warehouse: "/opt/spark/warehouse/default"
    spark.sql.catalog.local_original_iceberg: "org.apache.iceberg.spark.SparkCatalog"
    spark.sql.catalog.local_original_iceberg.type: "hadoop"
    spark.sql.catalog.local_original_iceberg.warehouse: "/opt/spark/warehouse/local_original_iceberg"
    spark.sql.catalog.external_catalog: "org.apache.iceberg.spark.SparkCatalog"
    spark.sql.catalog.external_catalog.type: "hadoop"
    spark.sql.catalog.external_catalog.warehouse: "/opt/spark/warehouse/external_catalog"
    #spark.sql.defaultCatalog: "local"
    spark.sql.catalog.external_catalog.metrics-reporter-impl: "org.apache.iceberg.metrics.LoggingMetricsReporter"
    #spark.master: "spark://spark-master:7077"
    spark.eventLog.enabled: "true"
    spark.eventLog.dir: "/opt/spark/spark-events"
    spark.history.fs.logDirectory: "/opt/spark/spark-events"
    spark.sql.adaptive.enabled: "false"
    spark.executor.cores: "1"
    spark.executor.memory: "4g"
    spark.executor.instances: "20"