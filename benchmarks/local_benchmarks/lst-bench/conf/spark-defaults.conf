spark.master                           spark://spark-master:7077
spark.eventLog.enabled                 true
spark.eventLog.dir                     /opt/spark/spark-events
spark.history.fs.logDirectory          /opt/spark/spark-events
spark.sql.adaptive.enabled             false
spark.executor.cores                   1
spark.executor.memory                  4g
spark.sql.thriftServer.port            10000
spark.sql.thriftServer.log.level       WARNING
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.hadoop.hive.metastore.uris=thrift://metastore:9083
spark.sql.catalog.local_original_iceberg=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.local_original_iceberg.type=hadoop
spark.sql.catalog.local_original_iceberg.warehouse=/opt/spark/warehouse/local_original_iceberg
spark.sql.catalog.external_catalog=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.external_catalog.type=hadoop
spark.sql.catalog.external_catalog.warehouse=/opt/spark/warehouse/external_catalog
spark.sql.catalog.external_catalog.metrics-reporter-impl=org.apache.iceberg.metrics.LoggingMetricsReporter
spark.executor.cores=1
spark.executor.memory=4g
#spark.executor.instances=20
# Number of cores per application
spark.cores.max=10

# Google Cloud Storage Setup
spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.google.cloud.auth.service.account.enable=true

# TODO: Set the path to your service account key file
#spark.hadoop.google.cloud.auth.service.account.json.keyfile=/home/eecs/chris_douglas/iceberg/benchmarks/local_benchmarks/lst-consistency-8dd2dfbea73a.json
spark.hadoop.google.cloud.auth.service.account.json.keyfile=/opt/spark/conf/gs_keyfile.json

# TODO: Set to our catalog implementation
spark.sql.catalog.gs_original_iceberg=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.gs_original_iceberg.type=hadoop
# Directory has to match catalog name
#spark.sql.catalog.gs_original_iceberg.warehouse=gs://gs_original_iceberg
spark.sql.catalog.gs_original_iceberg.warehouse=gs://lst-consistency
